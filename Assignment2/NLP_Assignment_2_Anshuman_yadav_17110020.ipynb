{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT-O-dsYRSUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout,SimpleRNN \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "import keras.utils as utils\n",
        "import re\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import math\n",
        "import codecs\n",
        "import random\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk import ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAVc9pyBbPUu",
        "colab_type": "text"
      },
      "source": [
        "# Classical **Apprroach**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIj4v5QpRXMG",
        "colab_type": "code",
        "outputId": "14108c89-d237-4163-bd12-060051221ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "f = open('speeches.txt', 'r', encoding='UTF-8')\n",
        "raw = f.read()\n",
        "raw = raw.replace(\"\\'\", \"\")\n",
        "raw = raw.replace(\",\", \"\")\n",
        "raw = raw.replace(\"\\r\\n\", \"\")\n",
        "raw = raw.replace(\"\\ufeff\",\"\")\n",
        "raw = re.sub(r'SPEECH \\d',r'',raw)\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHIoGfSXRXPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "special_chars = re.compile('[`~!@#$%^&*()+={}|\\[\\]:\";<>?,\\./“”]')\n",
        "raw_sentence = sent_tokenize(raw)\n",
        "sentences = []\n",
        "for item in raw_sentence:\n",
        "  text = item.replace(\"\\n\", \" \")\n",
        "  text = \"<s> \" + special_chars.sub(\"\", text) + \" </s>\"\n",
        "  text = text.lower()\n",
        "  sentences.append(' '.join(text.split()))\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLDHRynGxGhe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYq3EhyIxGTQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJbStyy0xGQR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jODX6lTFRXRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xtest = train_test_split(sentences, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57T5SBD1RXT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retngrams(xtrain,n):\n",
        "  dictk=dict()\n",
        "  count = 0\n",
        "  for sen in xtrain:\n",
        "    kgrams = ngrams(sen.split(), n)\n",
        "    for i in kgrams:\n",
        "      if(i not in dictk):\n",
        "        dictk[i]=1\n",
        "      else:\n",
        "        dictk[i]=dictk[i]+1\n",
        "      count=count+1\n",
        "  return(dictk,count)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAFlk4vORXVX",
        "colab_type": "code",
        "outputId": "ec5f1d33-8181-40c1-cacb-e28f7019120f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "igram = []\n",
        "for i in range(1,5):\n",
        "  igram.append(retngrams(xtrain,i))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s2MP1f-aCed",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2y9-qp5A1hY",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title MLE\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNjmoaKpRXYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MLE = []\n",
        "for i in range(4):\n",
        "  d = dict()\n",
        "  if(i == 0):\n",
        "    for j in igram[i][0]:\n",
        "      d[j] = igram[i][0][j]/igram[i][1]\n",
        "    MLE.append(d)\n",
        "  else:\n",
        "    for j in igram[i][0]:\n",
        "      d[j] = igram[i][0][j]/igram[i-1][0][j[:-1]]\n",
        "    MLE.append(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDxzCqt8xRAW",
        "colab_type": "code",
        "outputId": "010c5c8a-1fb5-445e-a215-7ac010da51aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sum(MLE[1].values())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5900.999999999846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DVLEyxtRXZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator(n,size, igram):\n",
        "  ans = \"<s>\"\n",
        "  sentence = [\"<s>\"]\n",
        "  if(n == 1):\n",
        "    keys = list(MLE[n-1].keys())\n",
        "    values = list(MLE[n-1].values())\n",
        "    rand = np.random.multinomial(1 , values , size=size)\n",
        "    for i in rand:\n",
        "      for j in range(len(keys)):\n",
        "        if(i[j] == 1):\n",
        "          if(keys[j][0] == \"<s>\"):\n",
        "            sentence.append(keys[j][0])\n",
        "            print(ans)\n",
        "            return\n",
        "          sentence.append(keys[j][0])\n",
        "          ans = ans + \" \" + keys[j][0]\n",
        "          if(keys[j][0] == \"</s>\"):\n",
        "            print(ans)\n",
        "            return\n",
        "            break\n",
        "    print(ans)\n",
        "    return       \n",
        "  else:\n",
        "    sentence=['<s>']\n",
        "    tempa=[]\n",
        "    tempb=[]\n",
        "    for i in range(n-1):\n",
        "      sentence=list(sentence)\n",
        "      keys = list(igram[i].keys())\n",
        "      values = list(igram[i].values())\n",
        "      for key in keys:\n",
        "        ls=list(key)\n",
        "        if(ls[:i]==sentence):\n",
        "          tempa.append(key)\n",
        "          tempb.append(igram[i][key])\n",
        "        rand=np.random.multinomial(1 , tempb , size=1)\n",
        "        for k in range(len(rand[0])):\n",
        "          if(rand[0][k]==1):\n",
        "            sentence=tempa[k]\n",
        "        tempa = []\n",
        "        tempb = []\n",
        "    sentence=list(sentence)\n",
        "    tempa=[]\n",
        "    tempb=[]\n",
        "    keys = list(igram[n-1].keys())\n",
        "    values = list(igram[n-1].values())\n",
        "    print(*sentence,end=' ')\n",
        "    for i in range(size):\n",
        "      for key in keys:\n",
        "        ls=list(key)\n",
        "          if(ls[:-1]==sentence):\n",
        "            tempa.append(key)\n",
        "            tempb.append(igram[n-1][key])\n",
        "        rand=np.random.multinomial(1 , tempb , size=1)\n",
        "        for k in range(len(rand[0])):\n",
        "          if(rand[0][k]==1):\n",
        "            print(list(tempa[k])[-1],end=' ')\n",
        "            sentence=list(tempa[k])[1:]\n",
        "        setence=list(sentence)\n",
        "        tempa=[]\n",
        "        tempb=[]    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRaLZ4JJbJMF",
        "colab_type": "text"
      },
      "source": [
        "# Sentence Generation and Perplexity **calculations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6m0xyeRRXeG",
        "colab_type": "code",
        "outputId": "b1ad1407-ef58-445d-d54f-6e2c6098472e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "def probab(sentence, n):\n",
        "  prob = 0\n",
        "  sentence = sentence.split(\" \")\n",
        "  for i in range(len(sentence)-n+1):\n",
        "    w = sentence[i:i+n]\n",
        "    prob += math.log(MLE[n-1][tuple(w)],2)\n",
        "  return math.pow(2,prob)\n",
        "\n",
        "def perplexity(tests, n):\n",
        "  prob = 0\n",
        "  len1 = 0\n",
        "  for i in tests:\n",
        "    try:\n",
        "      prob -= math.log(probab(i, n),2)\n",
        "    except:\n",
        "      prob -= 0\n",
        "    sentence = i.split(\" \")\n",
        "    len1 += len(sentence)-n-1\n",
        "  return math.pow(2, prob/len1)\n",
        "\n",
        "print(\"Unigram perplexity : \",perplexity(xtest, 1))\n",
        "print(\"Randomly generated Sentence from Unigram : \" )\n",
        "print(Generator(1,30,MLE))\n",
        "print(\" \")\n",
        "print(\"Bigram perplexity : \",perplexity(xtest, 2))\n",
        "print(\"Randomly generated Sentence from Bigram : \" )\n",
        "Generator(2,30,MLE)\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\"Trigram perplexity : \",perplexity(xtest, 3))\n",
        "print(\"Randomly generated Sentence from Trigram : \" )\n",
        "Generator(3,30,MLE)\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(\"Quadgram perplexity : \",perplexity(xtest, 4))\n",
        "\n",
        "print(\"Randomly generated Sentence from Quadgram : \" )\n",
        "print(Generator(4,30,MLE))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unigram perplexity :  222.83338830403525\n",
            "Randomly generated Sentence from Unigram : \n",
            "<s> this ankles ford that’s certain to badly room asked with all i’m many\n",
            "None\n",
            " \n",
            "Bigram perplexity :  2.3085702897936864\n",
            "Randomly generated Sentence from Bigram : \n",
            "<s> i intend to have the other laws are going up his friends were fighting everybody </s>  \n",
            " \n",
            "Trigram perplexity :  1.2051141445849718\n",
            "Randomly generated Sentence from Trigram : \n",
            "<s> both of them moving into mexico </s>  \n",
            " \n",
            "Quadgram perplexity :  1.0634054681063243\n",
            "Randomly generated Sentence from Quadgram : \n",
            "<s> first i said oh this is a common sense well thought out tax proposal that’s going to be negotiating our deals and they’re the — they’re the easiest </s> None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR6K_8WGbEKN",
        "colab_type": "text"
      },
      "source": [
        "# Neural **Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogKng8h2RXgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neural = []\n",
        "for i in xtrain:\n",
        "  neural.append(i.split())\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(neural)\n",
        "len_total= len(tokenizer.word_index) + 1\n",
        "train_neural = []\n",
        "for i in xtrain:\n",
        "  tokens = tokenizer.texts_to_sequences([i])[0]\n",
        "  for j in range(1, len(tokens)):\n",
        "        train_neural.append(tokens[:j+1])\n",
        "train_neural = np.array(pad_sequences(train_neural,maxlen=15, padding='pre'))\n",
        "predictors, label = train_neural[:,:-1],train_neural[:,-1]\n",
        "label = utils.to_categorical(label, num_classes=len_total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35hs_Wxfj1Ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a462819-c2f5-417c-c37e-555defb6eb00"
      },
      "source": [
        "test = retngrams(xtest,4)\n",
        "n_test = []\n",
        "for i in test[0].keys():\n",
        "  a = []\n",
        "  for j in i :\n",
        "    a.append(j)\n",
        "  n_test.append(a)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eGLWMcpjeZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "78f55dfa-3c1d-4fe9-a43e-c25ff791292d"
      },
      "source": [
        "from keras.layers import SimpleRNN\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(Embedding(len_total, 100, input_length=14))\n",
        "model_rnn.add(SimpleRNN(100))\n",
        "model_rnn.add(Dropout(0.2))\n",
        "model_rnn.add(Dense(len_total, activation='softmax'))\n",
        "\n",
        "model_rnn.summary()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 14, 100)           590300    \n",
            "_________________________________________________________________\n",
            "simple_rnn_10 (SimpleRNN)    (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 5903)              596203    \n",
            "=================================================================\n",
            "Total params: 1,206,603\n",
            "Trainable params: 1,206,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsw9Zu5QjecG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "1269b6a9-39d1-4220-9b7a-694b6a706bf4"
      },
      "source": [
        "model_rnn.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model_rnn.fit(predictors,label, batch_size=128, epochs=10)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/10\n",
            "122058/122058 [==============================] - 45s 367us/step - loss: 6.1897 - acc: 0.0540\n",
            "Epoch 2/10\n",
            "122058/122058 [==============================] - 43s 356us/step - loss: 5.6844 - acc: 0.0999\n",
            "Epoch 3/10\n",
            "122058/122058 [==============================] - 43s 356us/step - loss: 5.4161 - acc: 0.1264\n",
            "Epoch 4/10\n",
            "122058/122058 [==============================] - 43s 355us/step - loss: 5.2918 - acc: 0.1366\n",
            "Epoch 5/10\n",
            "122058/122058 [==============================] - 44s 357us/step - loss: 5.2202 - acc: 0.1445\n",
            "Epoch 6/10\n",
            "122058/122058 [==============================] - 44s 363us/step - loss: 5.1697 - acc: 0.1499\n",
            "Epoch 7/10\n",
            "122058/122058 [==============================] - 45s 368us/step - loss: 5.1342 - acc: 0.1543\n",
            "Epoch 8/10\n",
            "122058/122058 [==============================] - 45s 370us/step - loss: 5.1098 - acc: 0.1580\n",
            "Epoch 9/10\n",
            "122058/122058 [==============================] - 46s 378us/step - loss: 5.0927 - acc: 0.1608\n",
            "Epoch 10/10\n",
            "122058/122058 [==============================] - 45s 368us/step - loss: 5.0805 - acc: 0.1634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9996aa5630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-AoqZibWQS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator(text,model):\n",
        "  for j in range(15):\n",
        "    tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "    tokens = pad_sequences([tokens], maxlen= 14, padding='pre')\n",
        "    pred = model.predict_classes(tokens, verbose=0)\n",
        "    temp = \"\"\n",
        "    for tex, i in tokenizer.word_index.items():\n",
        "      if i == pred:\n",
        "        text += \" \" + tex\n",
        "        break\n",
        "  return(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX2oSVrHar0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKYQun8hasyS",
        "colab_type": "text"
      },
      "source": [
        "# **Sentence Generation for RNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCsOzS_XVMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fee84ba9-80db-450f-dac9-98a4cab64a1b"
      },
      "source": [
        "print(Generator(\"am\",model_rnn))\n",
        "print(Generator(\"i\",model_rnn))\n",
        "print(Generator(\"america\",model_rnn))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "am table table heros struggles heros gps takes bone changer excused killings prove dollar lost soul\n",
            "i table cool table ex-president 5 degenerates bit lakes dream bosses racial mountain resolutions america intelligence\n",
            "america table table 5 anti-ship vladimir gps better tools bit stamped heros handled many-- bless doesnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYPh0ravjeeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(len_total, 50, input_length=14))\n",
        "model_lstm.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model_lstm.add(Dense(40, activation='relu'))\n",
        "model_lstm.add(Dense(len_total, activation='softmax'))\n",
        "model_lstm.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9kbYjKAjegy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "d0ed58c3-ac85-4196-d190-74280a83e664"
      },
      "source": [
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm.fit(predictors,label, batch_size=128, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "122058/122058 [==============================] - 77s 632us/step - loss: 6.2339 - acc: 0.0545\n",
            "Epoch 2/10\n",
            "122058/122058 [==============================] - 77s 628us/step - loss: 5.6262 - acc: 0.1135\n",
            "Epoch 3/10\n",
            "122058/122058 [==============================] - 76s 620us/step - loss: 5.2599 - acc: 0.1452\n",
            "Epoch 4/10\n",
            "122058/122058 [==============================] - 76s 619us/step - loss: 5.0109 - acc: 0.1640\n",
            "Epoch 5/10\n",
            "122058/122058 [==============================] - 77s 627us/step - loss: 4.8232 - acc: 0.1767\n",
            "Epoch 6/10\n",
            "122058/122058 [==============================] - 78s 636us/step - loss: 4.6744 - acc: 0.1872\n",
            "Epoch 7/10\n",
            "122058/122058 [==============================] - 76s 624us/step - loss: 4.5457 - acc: 0.1963\n",
            "Epoch 8/10\n",
            "122058/122058 [==============================] - 77s 627us/step - loss: 4.4308 - acc: 0.2036\n",
            "Epoch 9/10\n",
            "104832/122058 [========================>.....] - ETA: 10s - loss: 4.3286 - acc: 0.2119"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obL_TaAWcN46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = Keras.sparse_categorical_crossentropy(y_true, y_pred)\n",
        "    perplexity = Keras.exp(cross_entropy)\n",
        "    return perplexity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir3TUwqsa8JP",
        "colab_type": "text"
      },
      "source": [
        "# `Sentence Generation for **LSTM**`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlMScZ4Cbky_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cceda7e0-1f93-4faa-a574-1819f03c433f"
      },
      "source": [
        "print(Generator(\"am\",model_lstm))\n",
        "print(Generator(\"i\",model_lstm))\n",
        "print(Generator(\"trump\",model_lstm))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "am the way i said i said i said i said i said i said i\n",
            "i said i said i said i said i said i said i said i said\n",
            "trump is a lot of money and i said i said i said i said i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7GS6Oy5bqZR",
        "colab_type": "text"
      },
      "source": [
        "By the looks of it, classical performs better, it is able to generate better sentencse which are grammatically correct and make sense as well, LSTM performs poor as of now, it may perform better if we tune it better. "
      ]
    }
  ]
}